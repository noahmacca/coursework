{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from util import get_normalized_data\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(object):\n",
    "    def __init__(self, M1, M2):\n",
    "        self.M1 = M1\n",
    "        self.M2 = M2\n",
    "        W = np.random.randn(M1, M2) / np.sqrt(M1 + M2)\n",
    "        b = np.zeros(M2)\n",
    "        self.W = tf.Variable(W.astype(np.float32))\n",
    "        self.b = tf.Variable(b.astype(np.float32))\n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return tf.nn.relu(tf.matmul(X, self.W) + self.b)\n",
    "    \n",
    "class ANN(object):\n",
    "    def __init__(self, hidden_layer_sizes, p_keep):\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.dropout_rates = p_keep\n",
    "    \n",
    "    def fit(self, X, Y, lr=10e-7, mu=0.99, decay=0.999, epochs=300, batch_sz=100):\n",
    "        # Make a validation set\n",
    "        X, Y = shuffle(X, Y)\n",
    "        X = X.astype(np.float32)\n",
    "        Y = Y.astype(np.int64)\n",
    "        Xvalid, Yvalid = X[-1000:], Y[-1000:]\n",
    "        X, Y = X[:-1000], Y[:-1000]\n",
    "        \n",
    "        # initialize hidden layers\n",
    "        N, D = X.shape\n",
    "        K = len(set(Y))\n",
    "        self.hidden_layers = []\n",
    "        M1 = D\n",
    "        for M2 in self.hidden_layer_sizes:\n",
    "            h = HiddenLayer(M1, M2)\n",
    "            self.hidden_layers.append(h)\n",
    "            M1 = M2\n",
    "        W = np.random.randn(M1, K) / np.sqrt(M1 + K)\n",
    "        b = np.zeros(K)\n",
    "        self.W = tf.Variable(W.astype(np.float32))\n",
    "        self.b = tf.Variable(b.astype(np.float32))\n",
    "        \n",
    "        # collect params for later use\n",
    "        self.params = [self.W, self.b]\n",
    "        for h in self.hidden_layers:\n",
    "            self.params += h.params\n",
    "        \n",
    "        # Set up functions and variables\n",
    "        inputs = tf.placeholder(tf.float32, shape=(None, D), name='inputs')\n",
    "        labels = tf.placeholder(tf.int64, shape=(None,), name='labels')\n",
    "        logits = self.forward(inputs) # define this below\n",
    "        \n",
    "        cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels))\n",
    "        train_op = tf.train.RMSPropOptimizer(lr, decay=decay, momentum=mu).minimize(cost)\n",
    "        prediction = self.predict(inputs) # define below\n",
    "        \n",
    "        n_batches = N//batch_sz\n",
    "        costs = []\n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as session:\n",
    "            session.run(init)\n",
    "            for i in range(epochs):\n",
    "                X, Y = shuffle(X, Y)\n",
    "                for j in range(n_batches):\n",
    "                    Xbatch = X[j*batch_sz:(j*batch_sz + batch_sz)]\n",
    "                    Ybatch = Y[j*batch_sz:(j*batch_sz + batch_sz)]\n",
    "                    \n",
    "                    session.run(train_op, feed_dict={inputs: Xbatch, labels: Ybatch})\n",
    "                    \n",
    "                    if j % 20 == 0:\n",
    "                        c = session.run(cost, feed_dict={inputs: Xvalid, labels: Yvalid})\n",
    "                    p = session.run(prediction, feed_dict={inputs: Xvalid})\n",
    "                        costs.append(c)\n",
    "                        e = error_rate(Yvalid, p)\n",
    "                        print(\"I:\", i, \"j:\", j, \"nb:\", n_batches, \"cost:\", c, \"error rate:\", e)\n",
    "        plt.plot(costs)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # no need to define different functions for train and predict\n",
    "        # tf.nn.dropout takes cae of the differences for us\n",
    "        Z = X\n",
    "        Z = tf.nn.dropout(Z, self.dropout_rates[0])\n",
    "        for h, p in zip(self.hidden_layers, self.dropout_rates[1:]):\n",
    "            Z = h.forward(Z)\n",
    "            Z = tf.nn.dropout(Z, p)\n",
    "        return tf.matmul(Z, self.W) + self.b\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pY = self.forward(X)\n",
    "        return tf.argmax(pY, 1)\n",
    "    \n",
    "    \n",
    "def error_rate(p, t):\n",
    "    return np.mean(p != t)\n",
    "\n",
    "def relu(a):\n",
    "    return a * (a > 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_normalized_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0 j: 0 nb: 410 cost: 2.46537 error rate: 0.897\n",
      "I: 0 j: 20 nb: 410 cost: 2.37853 error rate: 0.868\n",
      "I: 0 j: 40 nb: 410 cost: 2.18948 error rate: 0.772\n",
      "I: 0 j: 60 nb: 410 cost: 1.9654 error rate: 0.588\n",
      "I: 0 j: 80 nb: 410 cost: 1.6947 error rate: 0.488\n",
      "I: 0 j: 100 nb: 410 cost: 1.47736 error rate: 0.421\n",
      "I: 0 j: 120 nb: 410 cost: 1.20806 error rate: 0.336\n",
      "I: 0 j: 140 nb: 410 cost: 1.05685 error rate: 0.309\n",
      "I: 0 j: 160 nb: 410 cost: 0.91332 error rate: 0.291\n",
      "I: 0 j: 180 nb: 410 cost: 0.790022 error rate: 0.234\n",
      "I: 0 j: 200 nb: 410 cost: 0.738162 error rate: 0.234\n",
      "I: 0 j: 220 nb: 410 cost: 0.741937 error rate: 0.224\n",
      "I: 0 j: 240 nb: 410 cost: 0.656496 error rate: 0.222\n",
      "I: 0 j: 260 nb: 410 cost: 0.669905 error rate: 0.191\n",
      "I: 0 j: 280 nb: 410 cost: 0.608381 error rate: 0.176\n",
      "I: 0 j: 300 nb: 410 cost: 0.637044 error rate: 0.173\n",
      "I: 0 j: 320 nb: 410 cost: 0.574367 error rate: 0.154\n",
      "I: 0 j: 340 nb: 410 cost: 0.557694 error rate: 0.157\n",
      "I: 0 j: 360 nb: 410 cost: 0.540171 error rate: 0.146\n",
      "I: 0 j: 380 nb: 410 cost: 0.524234 error rate: 0.133\n",
      "I: 0 j: 400 nb: 410 cost: 0.512794 error rate: 0.134\n",
      "I: 1 j: 0 nb: 410 cost: 0.506558 error rate: 0.143\n",
      "I: 1 j: 20 nb: 410 cost: 0.454409 error rate: 0.133\n",
      "I: 1 j: 40 nb: 410 cost: 0.48065 error rate: 0.131\n",
      "I: 1 j: 60 nb: 410 cost: 0.482656 error rate: 0.136\n",
      "I: 1 j: 80 nb: 410 cost: 0.433574 error rate: 0.132\n",
      "I: 1 j: 100 nb: 410 cost: 0.461603 error rate: 0.138\n",
      "I: 1 j: 120 nb: 410 cost: 0.422133 error rate: 0.135\n",
      "I: 1 j: 140 nb: 410 cost: 0.382775 error rate: 0.125\n",
      "I: 1 j: 160 nb: 410 cost: 0.434141 error rate: 0.12\n",
      "I: 1 j: 180 nb: 410 cost: 0.404195 error rate: 0.13\n",
      "I: 1 j: 200 nb: 410 cost: 0.433889 error rate: 0.117\n",
      "I: 1 j: 220 nb: 410 cost: 0.414349 error rate: 0.124\n",
      "I: 1 j: 240 nb: 410 cost: 0.396615 error rate: 0.118\n",
      "I: 1 j: 260 nb: 410 cost: 0.412666 error rate: 0.109\n",
      "I: 1 j: 280 nb: 410 cost: 0.414659 error rate: 0.12\n",
      "I: 1 j: 300 nb: 410 cost: 0.37824 error rate: 0.11\n",
      "I: 1 j: 320 nb: 410 cost: 0.37246 error rate: 0.123\n",
      "I: 1 j: 340 nb: 410 cost: 0.382971 error rate: 0.1\n",
      "I: 1 j: 360 nb: 410 cost: 0.376629 error rate: 0.116\n",
      "I: 1 j: 380 nb: 410 cost: 0.368569 error rate: 0.11\n",
      "I: 1 j: 400 nb: 410 cost: 0.371025 error rate: 0.103\n",
      "I: 2 j: 0 nb: 410 cost: 0.356033 error rate: 0.096\n",
      "I: 2 j: 20 nb: 410 cost: 0.352861 error rate: 0.095\n",
      "I: 2 j: 40 nb: 410 cost: 0.336903 error rate: 0.109\n",
      "I: 2 j: 60 nb: 410 cost: 0.365716 error rate: 0.11\n",
      "I: 2 j: 80 nb: 410 cost: 0.382909 error rate: 0.094\n",
      "I: 2 j: 100 nb: 410 cost: 0.344703 error rate: 0.111\n",
      "I: 2 j: 120 nb: 410 cost: 0.330294 error rate: 0.113\n",
      "I: 2 j: 140 nb: 410 cost: 0.364247 error rate: 0.098\n",
      "I: 2 j: 160 nb: 410 cost: 0.339266 error rate: 0.102\n",
      "I: 2 j: 180 nb: 410 cost: 0.338513 error rate: 0.101\n",
      "I: 2 j: 200 nb: 410 cost: 0.366034 error rate: 0.1\n",
      "I: 2 j: 220 nb: 410 cost: 0.357803 error rate: 0.114\n",
      "I: 2 j: 240 nb: 410 cost: 0.33085 error rate: 0.094\n",
      "I: 2 j: 260 nb: 410 cost: 0.31906 error rate: 0.09\n",
      "I: 2 j: 280 nb: 410 cost: 0.327759 error rate: 0.108\n",
      "I: 2 j: 300 nb: 410 cost: 0.347211 error rate: 0.1\n",
      "I: 2 j: 320 nb: 410 cost: 0.336376 error rate: 0.101\n",
      "I: 2 j: 340 nb: 410 cost: 0.339868 error rate: 0.085\n",
      "I: 2 j: 360 nb: 410 cost: 0.317807 error rate: 0.104\n",
      "I: 2 j: 380 nb: 410 cost: 0.327758 error rate: 0.1\n",
      "I: 2 j: 400 nb: 410 cost: 0.343115 error rate: 0.095\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noP8HaOHmOjas/nsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119bf2a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann = ANN([500, 300], [0.8, 0.5, 0.5])\n",
    "ann.fit(X, Y, epochs=3, lr=50e-5, mu=0.99, decay=0.9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from util import get_normalized_data\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n"
     ]
    }
   ],
   "source": [
    "X, Y= get_normalized_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(object):\n",
    "    def __init__(self, M1, M2):\n",
    "        self.M1 = M1\n",
    "        self.M2 = M2\n",
    "        W = np.random.randn(M1, M2) / np.sqrt(M1 + M2)\n",
    "        b = np.zeros(M2)\n",
    "        self.W = tf.Variable(W.astype(np.float32))\n",
    "        self.b = tf.Variable(b.astype(np.float32))\n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return tf.nn.relu(tf.matmul(X, self.W) + self.b)\n",
    "    \n",
    "class ANN(object):\n",
    "    def __init__(self, hidden_layer_sizes, p_keep):\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.dropout_rates = p_keep\n",
    "        \n",
    "    def fit(self, X, Y, lr=10e-7, mu=0.99, decay=0.999, epochs=300, batch_sz=100):\n",
    "        # Make a validation set\n",
    "        X, Y = shuffle(X, Y)\n",
    "        X = X.astype(np.float32)\n",
    "        Y = Y.astype(np.int64)\n",
    "        Xvalid, Yvalid = X[-1000:], Y[-1000:]\n",
    "        X, Y = X[:-1000], Y[:-1000]\n",
    "        \n",
    "        # initialize hidden layers\n",
    "        N, D = X.shape\n",
    "        K = len(set(Y))\n",
    "        self.hidden_layers = []\n",
    "        M1 = D\n",
    "        for M2 in self.hidden_layer_sizes:\n",
    "            h = HiddenLayer(M1, M2)\n",
    "            self.hidden_layers.append(h)\n",
    "            M1 = M2\n",
    "        W = np.random.randn(M1, K) / np.sqrt(M1 + K)\n",
    "        b = np.zeros(K)\n",
    "        self.W = tf.Variable(W.astype(np.float32))\n",
    "        self.b = tf.Variable(b.astype(np.float32))\n",
    "        \n",
    "        # collect params for later use\n",
    "        self.params = [self.W, self.b]\n",
    "        for h in self.hidden_layers:\n",
    "            self.params += h.params\n",
    "            \n",
    "        # Set up functions and variables\n",
    "        inputs = tf.placeholder(tf.float32, shape=(None, D), name='inputs')\n",
    "        labels = tf.placeholder(tf.int64, shape=(None,), name='labels')\n",
    "        logits = self.forward(inputs)\n",
    "        \n",
    "        cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels))\n",
    "        train_op = tf.train.RMSPropOptimizer(lr, decay=decay, momentum=mu).minimize(cost)\n",
    "        prediction = self.predict(inputs)\n",
    "        \n",
    "        n_batches = N // batch_sz\n",
    "        costs = []\n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as session:\n",
    "            session.run(init)\n",
    "            for i in range(epochs):\n",
    "                X, Y = shuffle(X, Y)\n",
    "                for j in range(n_batches):\n",
    "                    Xbatch = X[j*batch_sz:(j*batch_sz+batch_sz)]\n",
    "                    Ybatch = Y[j*batch_sz:(j*batch_sz+batch_sz)]\n",
    "                    \n",
    "                    session.run(train_op, feed_dict={inputs: Xbatch, labels: Ybatch})\n",
    "                    \n",
    "                    if j % 20 == 0:\n",
    "                        c = session.run(cost, feed_dict={inputs: Xvalid, labels: Yvalid})\n",
    "                        p = session.run(prediction, feed_dict={inputs: Xvalid})\n",
    "                        costs.append(c)\n",
    "                        e = error_rate(Yvalid, p)\n",
    "                        print(\"i:\", i, \"j:\", j, \"nb:\", n_batches, \"cost:\", c, \"error rate:\", e)\n",
    "        plt.plot(costs)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # no need to define different functions for train and predict\n",
    "        # tf.nn.dropout takes care of the differences for us\n",
    "        Z = X\n",
    "        Z = tf.nn.dropout(Z, self.dropout_rates[0])\n",
    "        for h, p in zip(self.hidden_layers, self.dropout_rates[1:]):\n",
    "            Z = h.forward(Z)\n",
    "            Z = tf.nn.dropout(Z, p)\n",
    "        return tf.matmul(Z, self.W) + self.b\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pY = self.forward(X)\n",
    "        return tf.argmax(pY, 1)\n",
    "    \n",
    "\n",
    "def error_rate(p, t):\n",
    "    return np.mean(p != t)\n",
    "\n",
    "def relu(a):\n",
    "    return a * (a > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 j: 0 nb: 410 cost: 2.42415 error rate: 0.885\n",
      "i: 0 j: 20 nb: 410 cost: 2.2315 error rate: 0.82\n",
      "i: 0 j: 40 nb: 410 cost: 1.89259 error rate: 0.577\n",
      "i: 0 j: 60 nb: 410 cost: 1.46542 error rate: 0.409\n",
      "i: 0 j: 80 nb: 410 cost: 1.11346 error rate: 0.311\n",
      "i: 0 j: 100 nb: 410 cost: 0.884763 error rate: 0.278\n",
      "i: 0 j: 120 nb: 410 cost: 0.729267 error rate: 0.233\n",
      "i: 0 j: 140 nb: 410 cost: 0.753207 error rate: 0.218\n",
      "i: 0 j: 160 nb: 410 cost: 0.640591 error rate: 0.208\n",
      "i: 0 j: 180 nb: 410 cost: 0.613216 error rate: 0.169\n",
      "i: 0 j: 200 nb: 410 cost: 0.527146 error rate: 0.175\n",
      "i: 0 j: 220 nb: 410 cost: 0.542825 error rate: 0.15\n",
      "i: 0 j: 240 nb: 410 cost: 0.506788 error rate: 0.13\n",
      "i: 0 j: 260 nb: 410 cost: 0.487386 error rate: 0.127\n",
      "i: 0 j: 280 nb: 410 cost: 0.436766 error rate: 0.145\n",
      "i: 0 j: 300 nb: 410 cost: 0.450633 error rate: 0.129\n",
      "i: 0 j: 320 nb: 410 cost: 0.406126 error rate: 0.127\n",
      "i: 0 j: 340 nb: 410 cost: 0.402425 error rate: 0.12\n",
      "i: 0 j: 360 nb: 410 cost: 0.414929 error rate: 0.124\n",
      "i: 0 j: 380 nb: 410 cost: 0.436619 error rate: 0.118\n",
      "i: 0 j: 400 nb: 410 cost: 0.406951 error rate: 0.119\n",
      "i: 1 j: 0 nb: 410 cost: 0.384213 error rate: 0.128\n",
      "i: 1 j: 20 nb: 410 cost: 0.402145 error rate: 0.113\n",
      "i: 1 j: 40 nb: 410 cost: 0.341997 error rate: 0.112\n",
      "i: 1 j: 60 nb: 410 cost: 0.329384 error rate: 0.114\n",
      "i: 1 j: 80 nb: 410 cost: 0.34995 error rate: 0.103\n",
      "i: 1 j: 100 nb: 410 cost: 0.356316 error rate: 0.104\n",
      "i: 1 j: 120 nb: 410 cost: 0.362754 error rate: 0.11\n",
      "i: 1 j: 140 nb: 410 cost: 0.358486 error rate: 0.103\n",
      "i: 1 j: 160 nb: 410 cost: 0.353854 error rate: 0.111\n",
      "i: 1 j: 180 nb: 410 cost: 0.320658 error rate: 0.106\n",
      "i: 1 j: 200 nb: 410 cost: 0.326664 error rate: 0.102\n",
      "i: 1 j: 220 nb: 410 cost: 0.316034 error rate: 0.087\n",
      "i: 1 j: 240 nb: 410 cost: 0.308554 error rate: 0.1\n",
      "i: 1 j: 260 nb: 410 cost: 0.320016 error rate: 0.095\n",
      "i: 1 j: 280 nb: 410 cost: 0.298604 error rate: 0.097\n",
      "i: 1 j: 300 nb: 410 cost: 0.296343 error rate: 0.081\n",
      "i: 1 j: 320 nb: 410 cost: 0.297698 error rate: 0.11\n",
      "i: 1 j: 340 nb: 410 cost: 0.301108 error rate: 0.088\n",
      "i: 1 j: 360 nb: 410 cost: 0.30127 error rate: 0.082\n",
      "i: 1 j: 380 nb: 410 cost: 0.29455 error rate: 0.087\n",
      "i: 1 j: 400 nb: 410 cost: 0.300766 error rate: 0.084\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2e7be7f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann = ANN([500, 300], [0.8, 0.5, 0.5])\n",
    "ann.fit(X, Y, epochs=2, lr=10e-4, mu=0.99, decay=0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
