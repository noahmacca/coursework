{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression example\n",
    "- Boston housing prices; predicting a continuous value instead of a discrete label\n",
    "- only 404 training and 102 test samples\n",
    "- Features are on different scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 2us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
       "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
       "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
       "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
       "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
       "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
       "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
       "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
       "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
       "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
       "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
       "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
       "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
       "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
       "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
       "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
       "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
       "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
       "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
       "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
       "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
       "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
       "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
       "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
       "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
       "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
       "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
       "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
       "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
       "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
       "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
       "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
       "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
       "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
       "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
       "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
       "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data/=std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traina  very small network with two hidden layers, each with 64 units. Small networks mitigate overfitting\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# last layer being linear (no activation function) means the network can predict values in any range\n",
    "# mse loss function means 'mean squared error', the square of the difference between the predi tions and the targets\n",
    "# mae is the 'mean absolute error', the absoute value of the difference between the predictions and the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-fold cross-validation when the validation scores might have a high variance with regard to the validation split\n",
    "# (e.g. from having a small amount of data)\n",
    "import numpy as np\n",
    "k=4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "processing fold # 1\n",
      "processing fold # 2\n",
      "processing fold # 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "        train_data[(i+1) * num_val_samples:]],\n",
    "        axis=0\n",
    "    )\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "        train_targets[(i+1) * num_val_samples:]],\n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.129034951181695, 2.1307857673947175, 2.8914956196699992, 2.2987992320910537]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "processing fold # 1\n",
      "processing fold # 2\n",
      "processing fold # 3\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 150\n",
    "all_mae_histories = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "        train_data[(i+1) * num_val_samples:]],\n",
    "        axis=0\n",
    "    )\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "        train_targets[(i+1) * num_val_samples:]],\n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    all_mae_histories.append(history.history['mean_absolute_error'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mean_absolute_error'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.406537598902636,\n",
       " 3.645441683212129,\n",
       " 2.9927628299977522,\n",
       " 2.728326685751232,\n",
       " 2.543567678715923,\n",
       " 2.4541263946212166,\n",
       " 2.3734189917152078,\n",
       " 2.3101930421571133,\n",
       " 2.2537600844606707,\n",
       " 2.2164586251324945,\n",
       " 2.1776957639766605,\n",
       " 2.147705942097277,\n",
       " 2.097628372337165,\n",
       " 2.100185430876099,\n",
       " 2.0953135311406834,\n",
       " 2.0455946851484845,\n",
       " 2.066416012965413,\n",
       " 1.9954386536437685,\n",
       " 2.0047199135959737,\n",
       " 1.9745426838940912,\n",
       " 1.9444974664807715,\n",
       " 1.9374709695872694,\n",
       " 1.9234665541759024,\n",
       " 1.8927041905941349,\n",
       " 1.8996208886502206,\n",
       " 1.8732578252801801,\n",
       " 1.8975091838207183,\n",
       " 1.8616095816734994,\n",
       " 1.847884195669256,\n",
       " 1.83967790174799,\n",
       " 1.8048893880135943,\n",
       " 1.8162765058353791,\n",
       " 1.790982426983295,\n",
       " 1.771163819253248,\n",
       " 1.7428311630837596,\n",
       " 1.7481133977178693,\n",
       " 1.7408011162241692,\n",
       " 1.7470474113332162,\n",
       " 1.7361040965165242,\n",
       " 1.7251823475652008,\n",
       " 1.7253803325564947,\n",
       " 1.6804794014090358,\n",
       " 1.7040652727136516,\n",
       " 1.674258278148009,\n",
       " 1.6663240784465678,\n",
       " 1.614837192072727,\n",
       " 1.6637771908599552,\n",
       " 1.6461300869586053,\n",
       " 1.6260125849506641,\n",
       " 1.627411977686111,\n",
       " 1.5971201693657602,\n",
       " 1.6103867040608977,\n",
       " 1.58728552966228,\n",
       " 1.5789326919187414,\n",
       " 1.5783697590969576,\n",
       " 1.5996263353738063,\n",
       " 1.5681371976046672,\n",
       " 1.5710026143801095,\n",
       " 1.5537739998043174,\n",
       " 1.519322402013017,\n",
       " 1.5329334228345661,\n",
       " 1.5350435618126745,\n",
       " 1.501349172969856,\n",
       " 1.4877945186674792,\n",
       " 1.493775217446557,\n",
       " 1.4735144213481313,\n",
       " 1.5005396954690662,\n",
       " 1.47573454112503,\n",
       " 1.497129997011065,\n",
       " 1.4669747993890994,\n",
       " 1.4649303805316636,\n",
       " 1.4136902369288327,\n",
       " 1.4149011808260048,\n",
       " 1.45435495128726,\n",
       " 1.4396056619414404,\n",
       " 1.4326186209621996,\n",
       " 1.4018573572139927,\n",
       " 1.427528740549245,\n",
       " 1.4093841025144747,\n",
       " 1.3900647505675212,\n",
       " 1.4062597704405833,\n",
       " 1.3865619590967007,\n",
       " 1.3992996451878312,\n",
       " 1.3717243604534137,\n",
       " 1.3887429646532923,\n",
       " 1.3906476857638594,\n",
       " 1.3243162569039724,\n",
       " 1.383047011425786,\n",
       " 1.359752449462123,\n",
       " 1.354813747280108,\n",
       " 1.3299245755664586,\n",
       " 1.3404170977007046,\n",
       " 1.3257345574917179,\n",
       " 1.3382548904261573,\n",
       " 1.3235221086162152,\n",
       " 1.313489324975722,\n",
       " 1.3420987335762176,\n",
       " 1.3319454570808031,\n",
       " 1.310794466202802,\n",
       " 1.3159202046126814,\n",
       " 1.3043601558153386,\n",
       " 1.3138691692462454,\n",
       " 1.2951550499440814,\n",
       " 1.2946519953976372,\n",
       " 1.298460599219445,\n",
       " 1.29256275109332,\n",
       " 1.2777412368519472,\n",
       " 1.278671376382557,\n",
       " 1.262771753588132,\n",
       " 1.2361331316504147,\n",
       " 1.2694671175660868,\n",
       " 1.277494268055403,\n",
       " 1.2604525388270715,\n",
       " 1.243780014538529,\n",
       " 1.240966555702411,\n",
       " 1.228128445423869,\n",
       " 1.2471738841273998,\n",
       " 1.2368422557811927,\n",
       " 1.2140952993934304,\n",
       " 1.2179364772519656,\n",
       " 1.2342910778404461,\n",
       " 1.1854443243234463,\n",
       " 1.220560631736277,\n",
       " 1.1932504226272256,\n",
       " 1.1823848224315707,\n",
       " 1.1919623094029945,\n",
       " 1.1813920934995015,\n",
       " 1.2029568318880037,\n",
       " 1.1888352618752533,\n",
       " 1.167436118763272,\n",
       " 1.174570636780742,\n",
       " 1.1819034622053897,\n",
       " 1.1691713976387932,\n",
       " 1.1926753442279576,\n",
       " 1.1814471327825742,\n",
       " 1.1668020693382415,\n",
       " 1.1701318422953286,\n",
       " 1.1582802595085044,\n",
       " 1.1582415042930705,\n",
       " 1.1519406176242892,\n",
       " 1.1671682430966066,\n",
       " 1.1516400725141218,\n",
       " 1.1263404085297788,\n",
       " 1.1253042106974636,\n",
       " 1.1365991520016105,\n",
       " 1.1624435052619908,\n",
       " 1.12843917226634,\n",
       " 1.1257622700319825,\n",
       " 1.1073779924081104,\n",
       " 1.1316389710989723]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
    "\n",
    "average_mae_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.762699847127877"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "test_mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
