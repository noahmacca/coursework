{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('coursera': venv)",
   "metadata": {
    "interpreter": {
     "hash": "ca5ef231eb5e2cac5bdbd874ed8565127ee0e836ce38e9cc631c219438cb95f7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goals: deal with words that aren't present in this vocuabulary when working with other text sources\n",
    "# Also, read text files, work with defaultdict, and work with string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('WSJ_02-21.pos', 'r') as f:\n",
    "    lines = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\t\tWord \tTag\n\nline number 1: In\tIN\n\nline number 2: an\tDT\n\nline number 3: Oct.\tNNP\n\nline number 4: 19\tCD\n\nline number 5: review\tNN\n\n"
     ]
    }
   ],
   "source": [
    "# Print columns for reference\n",
    "print(\"\\t\\tWord\", \"\\tTag\\n\")\n",
    "\n",
    "# Print first five lines of the dataset\n",
    "for i in range(5):\n",
    "    print(f'line number {i+1}: {lines[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'In\\tIN\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Early\nEarnings\nEarth\nEarthquake\nEast\n"
     ]
    }
   ],
   "source": [
    "# Create a vocabulary from all words that appeared at least 2 times in the dataset\n",
    "\n",
    "# Get the words from each line in the dataset\n",
    "words = [line.split('\\t')[0] for line in lines]\n",
    "\n",
    "# Define defaultdict of type 'int'\n",
    "freq = defaultdict(int)\n",
    "\n",
    "# Count frequency of occurrence for each word in the dataset\n",
    "for word in words:\n",
    "        freq[word] += 1\n",
    "\n",
    "# Create the vocabulary by filtering the 'freq' dictionary\n",
    "vocab = [k for k, v in freq.items() if (v > 1 and k != '\\n')]\n",
    "vocab.sort()\n",
    "\n",
    "for i in range(4000, 4005):\n",
    "    print(vocab[i])\n",
    "\n",
    "# Generally would write the vocabulary to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the covab to a new corpus. We will have missing words. Classify the type of each unknown word and assign it a corresponding `unknown token`\n",
    "\n",
    "def assign_unk(word):\n",
    "    # Assign tokens to unknown words\n",
    "\n",
    "    punct = set(string.punctuation)\n",
    "\n",
    "    # Suffixes\n",
    "    noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
    "    verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
    "    adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
    "    adv_suffix = [\"ward\", \"wards\", \"wise\"]\n",
    "\n",
    "     # Loop the characters in the word, check if any is a digit\n",
    "    if any(char.isdigit() for char in word):\n",
    "        return \"--unk_digit--\"\n",
    "\n",
    "    # Loop the characters in the word, check if any is a punctuation character\n",
    "    elif any(char in punct for char in word):\n",
    "        return \"--unk_punct--\"\n",
    "\n",
    "    # Loop the characters in the word, check if any is an upper case character\n",
    "    elif any(char.isupper() for char in word):\n",
    "        return \"--unk_upper--\"\n",
    "\n",
    "    # Check if word ends with any noun suffix\n",
    "    elif any(word.endswith(suffix) for suffix in noun_suffix):\n",
    "        return \"--unk_noun--\"\n",
    "\n",
    "    # Check if word ends with any verb suffix\n",
    "    elif any(word.endswith(suffix) for suffix in verb_suffix):\n",
    "        return \"--unk_verb--\"\n",
    "\n",
    "    # Check if word ends with any adjective suffix\n",
    "    elif any(word.endswith(suffix) for suffix in adj_suffix):\n",
    "        return \"--unk_adj--\"\n",
    "\n",
    "    # Check if word ends with any adverb suffix\n",
    "    elif any(word.endswith(suffix) for suffix in adv_suffix):\n",
    "        return \"--unk_adv--\"\n",
    "    \n",
    "    # If none of the previous criteria is met, return plain unknown\n",
    "    return \"--unk--\"\n",
    "\n",
    "# By augmenting the dataset to include these unknown word tokens you are helping the tagger have a better idea of the appropriate tag for these words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the correct tag for a word\n",
    "def get_word_tag(line, vocab):\n",
    "    if not line.split():\n",
    "        word = '--n--'\n",
    "        tag = '--s--'\n",
    "    else:\n",
    "        word, tag = line.split()\n",
    "        if word not in vocab:\n",
    "            word = assign_unk(word)\n",
    "    return word, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('--n--', '--s--')"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "get_word_tag('\\n', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('In', 'IN')"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "get_word_tag('In\\tIN\\n', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('--unk--', 'NN')"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "get_word_tag('tardigrade\\tNN\\n', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('--unk_verb--', 'VB')"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "get_word_tag('scrutinize\\tVB\\n', vocab)"
   ]
  },
  {
   "source": [
    "# NLP_C2_W2_lecture_notebook_numpy.ipynb"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix using some tag information and then modify it\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just use a subset of tags\n",
    "tags = ['RB', 'NN', 'TO']\n",
    "\n",
    "# Count number of transitions from one to another tag. Use when working with tags only.\n",
    "\n",
    "# Emission is number of times a particular pair of (tag, word) appeared in the training dataset. Use when working with tags and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_counts = {\n",
    "    ('NN', 'NN'): 16241,\n",
    "    ('RB', 'RB'): 2263,\n",
    "    ('TO', 'TO'): 2,\n",
    "    ('NN', 'TO'): 5256,\n",
    "    ('RB', 'TO'): 855,\n",
    "    ('TO', 'NN'): 734,\n",
    "    ('NN', 'RB'): 2431,\n",
    "    ('RB', 'NN'): 358,\n",
    "    ('TO', 'RB'): 200\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# move these frequencies to numpy array\n",
    "\n",
    "num_tags = len(tags)\n",
    "transition_matrix = np.zeros((num_tags, num_tags))\n",
    "\n",
    "transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "transition_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['NN', 'RB', 'TO']"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "sorted_tags = sorted(tags)\n",
    "\n",
    "sorted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.6241e+04, 2.4310e+03, 5.2560e+03],\n",
       "       [3.5800e+02, 2.2630e+03, 8.5500e+02],\n",
       "       [7.3400e+02, 2.0000e+02, 2.0000e+00]])"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "# Fill matrix with correct values\n",
    "for i in range(num_tags):\n",
    "    for j in range(num_tags):\n",
    "        tag_tuple = (sorted_tags[i], sorted_tags[j])\n",
    "        transition_matrix[i,j] = transition_counts.get(tag_tuple)\n",
    "\n",
    "transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         NN      RB      TO\nNN  16241.0  2431.0  5256.0\nRB    358.0  2263.0   855.0\nTO    734.0   200.0     2.0\n"
     ]
    }
   ],
   "source": [
    "def print_matrix(matrix):\n",
    "    print(pd.DataFrame(matrix, index=sorted_tags, columns=sorted_tags))\n",
    "\n",
    "print_matrix(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        NN     RB     TO\nNN  1624.1  243.1  525.6\nRB    35.8  226.3   85.5\nTO    73.4   20.0    0.2\n"
     ]
    }
   ],
   "source": [
    "transition_matrix = transition_matrix/10\n",
    "\n",
    "print_matrix(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          NN        RB        TO\nNN  0.678745  0.101596  0.219659\nRB  0.102992  0.651036  0.245972\nTO  0.784188  0.213675  0.002137\n"
     ]
    }
   ],
   "source": [
    "rows_sum = transition_matrix.sum(axis=1, keepdims=True)\n",
    "transition_matrix = transition_matrix / rows_sum\n",
    "print_matrix(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "transition_matrix.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          NN        RB        TO\nNN  8.458964  0.101596  0.219659\nRB  0.102992  6.502088  0.245972\nTO  0.784188  0.213675  4.541167\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Copy transition matrix for for-loop example\n",
    "t_matrix_for = np.copy(transition_matrix)\n",
    "\n",
    "# Copy transition matrix for numpy functions example\n",
    "t_matrix_np = np.copy(transition_matrix)\n",
    "\n",
    "# Loop values in the diagonal\n",
    "for i in range(num_tags):\n",
    "    t_matrix_for[i, i] =  t_matrix_for[i, i] + math.log(rows_sum[i])\n",
    "\n",
    "# Print matrix\n",
    "print_matrix(t_matrix_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          NN        RB        TO\nNN  8.458964  0.101596  0.219659\nRB  0.102992  6.502088  0.245972\nTO  0.784188  0.213675  4.541167\n"
     ]
    }
   ],
   "source": [
    "d = np.diag(t_matrix_np)\n",
    "d = np.reshape(d, (3,1))\n",
    "d = d + np.vectorize(math.log)(rows_sum)\n",
    "\n",
    "np.fill_diagonal(t_matrix_np, d)\n",
    "\n",
    "print_matrix(t_matrix_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "t_matrix_for == t_matrix_np"
   ]
  }
 ]
}