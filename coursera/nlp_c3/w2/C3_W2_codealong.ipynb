{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Hidden State Activation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 1]\n [1 1]\n [1 1]]\n(3, 2)\n[[9 9 9]\n [9 9 9]\n [9 9 9]]\n(3, 3)\n[[1 1 9 9 9]\n [1 1 9 9 9]\n [1 1 9 9 9]]\n(3, 5)\n[[1 1 9 9 9]\n [1 1 9 9 9]\n [1 1 9 9 9]]\n(3, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Horizontal concatenation\n",
    "w_hh = np.full((3,2), 1)\n",
    "w_hx = np.full((3,3), 9)\n",
    "\n",
    "print(w_hh)\n",
    "print(w_hh.shape)\n",
    "print(w_hx)\n",
    "print(w_hx.shape)\n",
    "\n",
    "w_h1 = np.concatenate((w_hh, w_hx), axis=1)\n",
    "print(w_h1)\n",
    "print(w_h1.shape)\n",
    "\n",
    "w_h2 = np.hstack((w_hh, w_hx))\n",
    "print(w_h2)\n",
    "print(w_h2.shape)\n",
    "\n",
    "# can do similar with axis=0 or vstack"
   ]
  },
  {
   "source": [
    "# Remember, we're concatenating\n",
    "# W horizontally\n",
    "# parameters h and x vertically\n",
    "# ensure the separated + elementwise added result is the same as the concatted version\n",
    "\n",
    "w_hh = np.full((3, 2), 1)\n",
    "w_hx = np.full((3, 3), 9)\n",
    "h_t_prev = np.full((2,  1), 1)\n",
    "x_t = np.full((3, 1), 9)\n",
    "\n",
    "stack_1 = np.hstack((w_hh, w_hx))\n",
    "stack_2 = np.vstack((h_t_prev, x_t))\n",
    "\n",
    "print('formula 1')\n",
    "print('term1', stack_1)\n",
    "print('term2', stack_2)\n",
    "formula_1 = np.matmul(np.hstack((w_hh, w_hx)), np.vstack((h_t_prev, x_t)))\n",
    "print('output')\n",
    "print(formula_1)\n",
    "\n",
    "# formula 2\n",
    "mul_1 = np.matmul(w_hh, h_t_prev)\n",
    "mul_2 = np.matmul(w_hx, x_t)\n",
    "print('formula 2')\n",
    "print('term1', mul_1)\n",
    "print('term2', mul_2)\n",
    "\n",
    "formula_2 = np.matmul(w_hh, h_t_prev) + np.matmul(w_hx, x_t)\n",
    "print('output')\n",
    "print(formula_2)\n",
    "\n",
    "\n",
    "print(\"-- Verify --\")\n",
    "print(\"Results are the same :\", np.allclose(formula_1, formula_2))\n",
    "\n",
    "# Try adding a sigmoid activation function and bias term as a final check\n",
    "# Activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Bias and check\n",
    "b = np.random.standard_normal((formula_1.shape[0],1))\n",
    "print(\"Formula 1 Output:\\n\",sigmoid(formula_1+b))\n",
    "print(\"Formula 2 Output:\\n\",sigmoid(formula_2+b))\n",
    "\n",
    "all_close = np.allclose(sigmoid(formula_1+b), sigmoid(formula_2+b))\n",
    "print(\"Results after activation are the same :\",all_close)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "formula 1\nterm1 [[1 1 9 9 9]\n [1 1 9 9 9]\n [1 1 9 9 9]]\nterm2 [[1]\n [1]\n [9]\n [9]\n [9]]\noutput\n[[245]\n [245]\n [245]]\nformula 2\nterm1 [[2]\n [2]\n [2]]\nterm2 [[243]\n [243]\n [243]]\noutput\n[[245]\n [245]\n [245]]\n-- Verify --\nResults are the same : True\nFormula 1 Output:\n [[1.]\n [1.]\n [1.]]\nFormula 2 Output:\n [[1.]\n [1.]\n [1.]]\nResults after activation are the same : True\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# JAX numpy and perplexity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import trax\n",
    "import trax.fastmath.numpy as np\n",
    "\n",
    "trax.supervised.trainer_lib.init_random_number_generators(32)\n",
    "numpy.random.seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.29043624 0.38836719 0.12730549 0.21281151 0.75505369 0.57887068\n  0.63183171 0.9575624  0.09425337 0.12772689]\n [0.40667553 0.22271941 0.53159447 0.83057898 0.60421553 0.18538948\n  0.38130853 0.28346655 0.70331245 0.25379794]\n [0.76139101 0.27705392 0.04512082 0.94255551 0.51623923 0.74118788\n  0.59841033 0.99493805 0.15958447 0.41761247]\n [0.4993524  0.68251486 0.74356294 0.04570872 0.5659992  0.95207681\n  0.86689532 0.20598575 0.61122462 0.4219096 ]\n [0.45027546 0.04400528 0.00684583 0.50835038 0.38884269 0.57835584\n  0.1565324  0.8933882  0.01109693 0.76347618]]\n<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "numpy_array = numpy.random.random((5, 10))\n",
    "print(numpy_array)\n",
    "print(type(numpy_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.29043624 0.3883672  0.1273055  0.21281151 0.7550537  0.5788707\n  0.6318317  0.9575624  0.09425337 0.12772688]\n [0.40667552 0.22271942 0.53159446 0.830579   0.6042155  0.18538949\n  0.38130853 0.28346655 0.70331246 0.25379795]\n [0.761391   0.27705392 0.04512082 0.9425555  0.5162392  0.7411879\n  0.5984103  0.9949381  0.15958448 0.41761246]\n [0.4993524  0.68251485 0.74356294 0.04570872 0.5659992  0.9520768\n  0.8668953  0.20598575 0.6112246  0.4219096 ]\n [0.45027545 0.04400528 0.00684583 0.5083504  0.3888427  0.57835585\n  0.1565324  0.8933882  0.01109693 0.7634762 ]]\n<class 'jax.interpreters.xla._DeviceArray'>\n"
     ]
    }
   ],
   "source": [
    "trax_numpy_array = np.array(numpy_array)\n",
    "print(trax_numpy_array)\n",
    "print(type(trax_numpy_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(32, 64, 256)\n(32, 64)\n"
     ]
    }
   ],
   "source": [
    "from trax import layers as tl\n",
    "\n",
    "predictions = numpy.load('predictions.npy')\n",
    "targets = numpy.load('targets.npy')\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "targets = np.array(targets)\n",
    "\n",
    "print(predictions.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(32, 64, 256)\n"
     ]
    }
   ],
   "source": [
    "reshaped_targets = tl.one_hot(targets, predictions.shape[-1])\n",
    "print(reshaped_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(32, 64)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([[ -5.396545  ,  -1.0311184 ,  -0.66916656, ...,\n",
       "              -22.37673   , -23.18771   , -21.843483  ],\n",
       "             [ -4.5857706 ,  -1.1341286 ,  -8.538033  , ...,\n",
       "              -20.15686   , -26.837097  , -23.57502   ],\n",
       "             [ -5.2223887 ,  -1.2824144 ,  -0.17312431, ...,\n",
       "              -21.328228  , -19.854412  , -33.88444   ],\n",
       "             ...,\n",
       "             [ -5.396545  , -17.291681  ,  -4.360766  , ...,\n",
       "              -20.825802  , -21.065838  , -22.443115  ],\n",
       "             [ -5.9313164 , -14.247417  ,  -0.2637329 , ...,\n",
       "              -26.743248  , -18.38433   , -22.355278  ],\n",
       "             [ -5.670536  ,  -0.10595131,   0.        , ...,\n",
       "              -23.332523  , -28.087376  , -23.878807  ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "total_log_ppx = np.sum(predictions * reshaped_targets, axis=-1)\n",
    "print(total_log_ppx.shape)\n",
    "total_log_ppx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "non_pad has shape: (32, 64)\nnon_pad looks like: [[1. 1. 1. ... 0. 0. 0.]\n [1. 1. 1. ... 0. 0. 0.]\n [1. 1. 1. ... 0. 0. 0.]\n ...\n [1. 1. 1. ... 0. 0. 0.]\n [1. 1. 1. ... 0. 0. 0.]\n [1. 1. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# account for perplexity\n",
    "non_pad = 1.0 - np.equal(targets, 0)\n",
    "print('non_pad has shape:', non_pad.shape)\n",
    "print('non_pad looks like:', non_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "real perplexity still has shape: (32, 64)\n[[ -5.396545    -1.0311184   -0.66916656 ... -22.37673    -23.18771\n  -21.843483  ]\n [ -4.5857706   -1.1341286   -8.538033   ... -20.15686    -26.837097\n  -23.57502   ]\n [ -5.2223887   -1.2824144   -0.17312431 ... -21.328228   -19.854412\n  -33.88444   ]\n ...\n [ -5.396545   -17.291681    -4.360766   ... -20.825802   -21.065838\n  -22.443115  ]\n [ -5.9313164  -14.247417    -0.2637329  ... -26.743248   -18.38433\n  -22.355278  ]\n [ -5.670536    -0.10595131   0.         ... -23.332523   -28.087376\n  -23.878807  ]]\n[[ -5.396545    -1.0311184   -0.66916656 ...  -0.          -0.\n   -0.        ]\n [ -4.5857706   -1.1341286   -8.538033   ...  -0.          -0.\n   -0.        ]\n [ -5.2223887   -1.2824144   -0.17312431 ...  -0.          -0.\n   -0.        ]\n ...\n [ -5.396545   -17.291681    -4.360766   ...  -0.          -0.\n   -0.        ]\n [ -5.9313164  -14.247417    -0.2637329  ...  -0.          -0.\n   -0.        ]\n [ -5.670536    -0.10595131   0.         ...  -0.          -0.\n   -0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# by computing produt of total log perpexity and the non_pad tensor, we remove the effect of padding\n",
    "real_log_ppx = total_log_ppx * non_pad\n",
    "print('real perplexity still has shape:', real_log_ppx.shape)\n",
    "print(total_log_ppx)\n",
    "print(real_log_ppx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "log perplexity 2.328121\nperplexity 10.258647\n"
     ]
    }
   ],
   "source": [
    "log_ppx = np.sum(real_log_ppx) / np.sum(non_pad)\n",
    "log_ppx = -log_ppx\n",
    "print('log perplexity', log_ppx)\n",
    "print('perplexity', np.exp(log_ppx))"
   ]
  },
  {
   "source": [
    "# Vanilla RNNs, GRUs and the scan function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from time import perf_counter\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward method\n",
    "# Embedding size: 128\n",
    "# Hidden state size: (16,1)\n",
    "# W is (h_dim, emb + h_dim)\n",
    "# b_ is (h_dim, 1)\n",
    "# h_t is (h_dim,1)\n",
    "# h_0 is a vector of zeros\n",
    "random.seed(10)                 # Random seed, so your results match ours\n",
    "emb = 128                       # Embedding size\n",
    "T = 256                         # Number of variables in the sequences\n",
    "h_dim = 16                      # Hidden state dimension\n",
    "h_0 = np.zeros((h_dim, 1))      # Initial hidden state\n",
    "# Random initialization of weights and biases\n",
    "w1 = random.standard_normal((h_dim, emb+h_dim))\n",
    "w2 = random.standard_normal((h_dim, emb+h_dim))\n",
    "w3 = random.standard_normal((h_dim, emb+h_dim))\n",
    "b1 = random.standard_normal((h_dim, 1))\n",
    "b2 = random.standard_normal((h_dim, 1))\n",
    "b3 = random.standard_normal((h_dim, 1))\n",
    "X = random.standard_normal((T, emb, 1))\n",
    "weights = [w1, w2, w3, b1, b2, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_V_RNN(inputs, weights):\n",
    "    x, h_t = inputs\n",
    "    wh, _, _, bh, _, _ = weights\n",
    "\n",
    "    h_t = np.dot(wh, np.concatenate([h_t, x])) + bh\n",
    "    h_t = sigmoid(h_t)\n",
    "\n",
    "    return h_t, h_t\n",
    "\n",
    "def forward_GRU(inputs, weighst):\n",
    "    x, h_t = inputs\n",
    "\n",
    "    wu, wr, wc, bu, br, bc = weights\n",
    "\n",
    "    # Update gate\n",
    "    u = np.dot(wu, np.concatenate([h_t, x])) + bu\n",
    "    u = sigmoid(u)\n",
    "\n",
    "    # Relevance gate\n",
    "    r = np.dot(wr, np.concatenate([h_t, x])) + br\n",
    "    r = sigmoid(r)\n",
    "\n",
    "    # Candidate hidden state\n",
    "    c = np.dot(wc, np.concatenate([r * h_t, x])) + bc\n",
    "    c = np.tanh(c)\n",
    "\n",
    "    h_t = u * c + (1 - u)*h_t\n",
    "    return h_t, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 9.77779014e-01],\n",
       "       [-9.97986240e-01],\n",
       "       [-5.19958083e-01],\n",
       "       [-9.99999886e-01],\n",
       "       [-9.99707004e-01],\n",
       "       [-3.02197037e-04],\n",
       "       [-9.58733503e-01],\n",
       "       [ 2.10804828e-02],\n",
       "       [ 9.77365398e-05],\n",
       "       [ 9.99833090e-01],\n",
       "       [ 1.63200940e-08],\n",
       "       [ 8.51874303e-01],\n",
       "       [ 5.21399924e-02],\n",
       "       [ 2.15495959e-02],\n",
       "       [ 9.99878828e-01],\n",
       "       [ 9.77165472e-01]])"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "forward_GRU([X[1],h_0], weights)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3, scan function\n",
    "# Takes fn, elems (for each time step) x, weights (for fn), and h_0 (initial hidden state)\n",
    "\n",
    "def scan(fn, elems, weights, h_0=None):\n",
    "    h_t = h_0\n",
    "    ys = []\n",
    "    for x in elems:\n",
    "        y, h_t = fn([x, h_t], weights)\n",
    "        ys.append(y)\n",
    "    return ys, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It took 6.64ms for vanilla RNN forward\n"
     ]
    }
   ],
   "source": [
    "# Comparison between vanilla RNNS and GRUs. Need a forward method and some way of\n",
    "# scanning through all elements\n",
    "# Compute forward prop for sequence with 256 time steps\n",
    "\n",
    "# Vanilla RNNs\n",
    "tic = perf_counter()\n",
    "ys, h_T = scan(forward_V_RNN, X, weights, h_0)\n",
    "toc = perf_counter()\n",
    "RNN_time = (toc-tic)*1000\n",
    "print(f'It took {RNN_time:.2f}ms for vanilla RNN forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It took 12.58ms to run the forward method for the GRU.\n"
     ]
    }
   ],
   "source": [
    "# GRUs\n",
    "tic = perf_counter()\n",
    "ys, h_T = scan(forward_GRU, X, weights, h_0)\n",
    "toc = perf_counter()\n",
    "GRU_time=(toc-tic)*1000\n",
    "print (f\"It took {GRU_time:.2f}ms to run the forward method for the GRU.\")"
   ]
  },
  {
   "source": [
    "# Creating a GRU model using Trax"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Serial[\n  Dense_128\n  Relu\n  Dense_10\n  LogSoftmax\n]\n"
     ]
    }
   ],
   "source": [
    "import trax\n",
    "from trax import layers as tl\n",
    "mlp = tl.Serial(\n",
    "    tl.Dense(128),\n",
    "    tl.Relu(),\n",
    "    tl.Dense(10),\n",
    "    tl.LogSoftmax()\n",
    ")\n",
    "\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New layers needed for GRU\n",
    "# ShiftRight: Shifts tensor to t he right by padding on axis 1. Mode refers to the context in which the model is being used ('train', 'eval', or 'predict', defaults to train)\n",
    "# Embedding: Maps discrete tokens to vectors. It will have shape (vocab_length X dimension of output vectors). The dimension of output vectors (also called d_feature) is the number of elements in the word embedding\n",
    "# GRU: Leverages GRUCell. Specify number of GRU units, which should match number of elements in the word embedding. To stack two consecutive GRU layers, ist can be done with python  list comprehension\n",
    "# Dense: Vanilla dense layer\n",
    "# LogSoftMax: Log Softmax Function\n",
    "\n",
    "mode = 'train'\n",
    "vocab_size = 256\n",
    "model_dimension =  512\n",
    "n_layers = 2\n",
    "GRU = tl.Serial(\n",
    "    tl.ShiftRight(mode=mode),\n",
    "    tl.Embedding(vocab_size=vocab_size, d_feature=model_dimension),\n",
    "    [tl.GRU(n_units=model_dimension) for _ in range(n_layers)],\n",
    "    tl.Dense(n_units=vocab_size),\n",
    "    tl.LogSoftmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total layers: 6\n\n===========\nSerial.sublayers_0: ShiftRight(1)\n\n===========\nSerial.sublayers_1: Embedding_256_512\n\n===========\nSerial.sublayers_2: GRU_512\n\n===========\nSerial.sublayers_3: GRU_512\n\n===========\nSerial.sublayers_4: Dense_256\n\n===========\nSerial.sublayers_5: LogSoftmax\n\n"
     ]
    }
   ],
   "source": [
    "def show_layers(model, layer_prefix='Serial.sublayers'):\n",
    "    print(f'Total layers: {len(model.sublayers)}\\n')\n",
    "    for i in range(len(model.sublayers)):\n",
    "        print('===========')\n",
    "        print(f'{layer_prefix}_{i}: {model.sublayers[i]}\\n')\n",
    "\n",
    "show_layers(GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}