{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain stack semantics in Trax\n",
    "# Select and Residual operate on elements in the stack\n",
    "\n",
    "import numpy as np\n",
    "from trax import layers as tl\n",
    "from trax import shapes\n",
    "from trax import fastmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack example\n",
    "\n",
    "def Addition():\n",
    "    layer_name = \"Addition\"\n",
    "    \n",
    "    def func(x, y):\n",
    "        return x + y\n",
    "    \n",
    "    return tl.Fn(layer_name, func)\n",
    "\n",
    "add = Addition()\n",
    "\n",
    "print(add.name)\n",
    "print(add.n_in)\n",
    "print(add.n_out)\n",
    "\n",
    "x = np.array([3])\n",
    "y = np.array([4])\n",
    "print(x)\n",
    "print(y)\n",
    "z = add((x, y))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Multiplication():\n",
    "    layer_name = \"Multiplication\"\n",
    "    \n",
    "    def func(x, y):\n",
    "        return x * y\n",
    "    \n",
    "    return tl.Fn(layer_name, func)\n",
    "\n",
    "mul = Multiplication()\n",
    "\n",
    "print(mul.name)\n",
    "print(mul.n_in)\n",
    "print(mul.n_out)\n",
    "\n",
    "x = np.array([7])\n",
    "y = np.array([15])\n",
    "print(x)\n",
    "print(y)\n",
    "z = mul((x, y))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial = tl.Serial(\n",
    "    Addition(), Multiplication(), Addition() # (3 + 4) * 15 + 3\n",
    ")\n",
    "x = (np.array([3]), np.array([4]), np.array([15]), np.array([3]))\n",
    "\n",
    "serial.init(shapes.signature(x))\n",
    "\n",
    "print(\"Serial Model\")\n",
    "print(serial)\n",
    "print(serial.name)\n",
    "print(serial.sublayers)\n",
    "print(serial.n_in)\n",
    "print(serial.n_out)\n",
    "print(x)\n",
    "print(serial(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tl.Select combinator\n",
    "\n",
    "serial = tl.Serial(tl.Select([0,1, 0, 1]), Addition(), Multiplication(), Addition())\n",
    "x = (np.array([3]), np.array([4]))\n",
    "\n",
    "serial.init(shapes.signature(x))\n",
    "\n",
    "print(serial)\n",
    "print(serial.name)\n",
    "print(serial.sublayers)\n",
    "print(serial.n_in)\n",
    "print(serial.n_out)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(serial(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial = tl.Serial(\n",
    "    tl.Select([0, 1, 0, 1]), Addition(), tl.Select([0], n_in=2), Multiplication()\n",
    ")\n",
    "\n",
    "x = (np.array([3]), np.array([4]))\n",
    "serial.init(shapes.signature(x))\n",
    "print(x)\n",
    "print(serial(x))\n",
    "\n",
    "# Select copies the inputs in  order to be used further along in the  stack of operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tl.Residual combinator. Residual networks make deep models easier to train.\n",
    "# Residual computes the element-wise sum of the stack-top input with the output\n",
    "# of the layer series\n",
    "\n",
    "serial = tl.Serial(\n",
    "    tl.Select([0, 1, 0, 1]),\n",
    "    tl.Residual(Addition())\n",
    ")\n",
    "\n",
    "print(serial)\n",
    "\n",
    "x1 = np.array([3])\n",
    "x2 = np.array([4])\n",
    "\n",
    "print((x1, x2))\n",
    "print(serial((x1, x2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU Scores\n",
    "- Closer to 1 is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "nltk.download('punkt')\n",
    "import math\n",
    "from collections import Counter\n",
    "import sacrebleu\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brevity Penalty\n",
    "ref_length= np.ones(100)\n",
    "can_length = np.linspace(1.5, 0.5, 100)\n",
    "x = ref_length / can_length\n",
    "y =  1 - x\n",
    "y = np.exp(y)\n",
    "y = np.minimum(np.ones(y.shape), y)\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "lines = ax.plot(x, y)\n",
    "ax.set(\n",
    "    xlabel='ratio of the length of the reference to the candidate text',\n",
    "    ylabel='Brevity Penalty'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"1-gram\": 0.8, \"2-gram\": 0.7, \"3-gram\": 0.6, \"4-gram\": 0.5}\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "bars = ax.bar(names, values)\n",
    "ax.set(ylabel=\"N-gram precision\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"1-gram\": 0.8, \"2-gram\": 0.77, \"3-gram\": 0.74, \"4-gram\": 0.71}\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "bars = ax.bar(names, values)\n",
    "ax.set(ylabel=\"Modified N-gram precision\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# When the n-gram precision is multiplied by the BP, then the exponential\n",
    "# decay of n-grams is almost fully compensated. The BLEU score corresponds\n",
    "# to a geometric average of this modified n-gram precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example calculation\n",
    "reference = \"The NASA Opportunity rover is battling a massive dust storm on planet Mars.\"\n",
    "candidate_1 = \"The Opportunity rover is combating a big sandstorm on planet Mars.\"\n",
    "candidate_2 = \"A NASA rover is fighting a massive storm on planet Mars.\"\n",
    "\n",
    "tokenized_ref = nltk.word_tokenize(reference.lower())\n",
    "tokenized_cand_1 = nltk.word_tokenize(candidate_1.lower())\n",
    "tokenized_cand_2 = nltk.word_tokenize(candidate_2.lower())\n",
    "\n",
    "print(f\"{reference} -> {tokenized_ref}\")\n",
    "print(\"\\n\")\n",
    "print(f\"{candidate_1} -> {tokenized_cand_1}\")\n",
    "print(\"\\n\")\n",
    "print(f\"{candidate_2} -> {tokenized_cand_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brevity_penalty(candidate, reference):\n",
    "    ref_length = len(reference)\n",
    "    can_length = len(candidate)\n",
    "    \n",
    "    if ref_length < can_length:\n",
    "        BP = 1\n",
    "    else:\n",
    "        penalty = 1 - (ref_length / can_length)\n",
    "        BP = np.exp(penalty)\n",
    "    \n",
    "    return BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_precision(candidate, reference):\n",
    "    \"\"\"\n",
    "    Clipped precision function given a original and a machine translated sentences\n",
    "    \"\"\"\n",
    "\n",
    "    clipped_precision_score = []\n",
    "    \n",
    "    for i in range(1, 5):\n",
    "        ref_n_gram = Counter(ngrams(reference,i))\n",
    "        cand_n_gram = Counter(ngrams(candidate,i))\n",
    "\n",
    "        c = sum(cand_n_gram.values())\n",
    "        \n",
    "        for j in cand_n_gram: # for every n-gram up to 4 in candidate text\n",
    "            if j in ref_n_gram: # check if it is in the reference n-gram\n",
    "                if cand_n_gram[j] > ref_n_gram[j]: # if the count of the candidate n-gram is bigger\n",
    "                                                   # than the corresponding count in the reference n-gram,\n",
    "                    cand_n_gram[j] = ref_n_gram[j] # then set the count of the candidate n-gram to be equal\n",
    "                                                   # to the reference n-gram\n",
    "            else:\n",
    "                cand_n_gram[j] = 0 # else set the candidate n-gram equal to zero\n",
    "\n",
    "        clipped_precision_score.append(sum(cand_n_gram.values())/c)\n",
    "\n",
    "    weights =[0.25]*4\n",
    "\n",
    "    s = (w_i * math.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\n",
    "    s = math.exp(math.fsum(s))\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(candidate, reference):\n",
    "    BP = brevity_penalty(candidate, reference)\n",
    "    precision = clipped_precision(candidate, reference)\n",
    "    return BP * precision\n",
    "\n",
    "print(\n",
    "    \"Results reference versus candidate 1 our own code BLEU: \",\n",
    "    round(bleu_score(tokenized_cand_1, tokenized_ref) * 100, 1),\n",
    ")\n",
    "print(\n",
    "    \"Results reference versus candidate 2 our own code BLEU: \",\n",
    "    round(bleu_score(tokenized_cand_2, tokenized_ref) * 100, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Results reference versus candidate 1 sacrebleu library BLEU: \",\n",
    "    round(sacrebleu.corpus_bleu(candidate_1, reference).score, 1),\n",
    ")\n",
    "print(\n",
    "    \"Results reference versus candidate 2 sacrebleu library BLEU: \",\n",
    "    round(sacrebleu.corpus_bleu(candidate_2, reference).score, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the raw data\n",
    "wmt19_src = open(\"wmt19_src.txt\", \"rU\")\n",
    "wmt19_src_1 = wmt19_src.read()\n",
    "wmt19_src.close()\n",
    "wmt19_ref = open(\"wmt19_ref.txt\", \"rU\")\n",
    "wmt19_ref_1 = wmt19_ref.read()\n",
    "wmt19_ref.close()\n",
    "wmt19_can = open(\"wmt19_can.txt\", \"rU\")\n",
    "wmt19_can_1 = wmt19_can.read()\n",
    "wmt19_can.close()\n",
    "\n",
    "tokenized_corpus_src = nltk.word_tokenize(wmt19_src_1.lower())\n",
    "tokenized_corpus_ref = nltk.word_tokenize(wmt19_ref_1.lower())\n",
    "tokenized_corpus_cand = nltk.word_tokenize(wmt19_can_1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"English source text:\")\n",
    "print(\"\\n\")\n",
    "print(f\"{wmt19_src_1[0:170]} -> {tokenized_corpus_src[0:30]}\")\n",
    "print(\"\\n\")\n",
    "print(\"German reference translation:\")\n",
    "print(\"\\n\")\n",
    "print(f\"{wmt19_ref_1[0:219]} -> {tokenized_corpus_ref[0:35]}\")\n",
    "print(\"\\n\")\n",
    "print(\"German machine translation:\")\n",
    "print(\"\\n\")\n",
    "print(f\"{wmt19_can_1[0:199]} -> {tokenized_corpus_cand[0:29]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Results reference versus candidate 1 our own BLEU implementation: \",\n",
    "    round(bleu_score(tokenized_corpus_cand, tokenized_corpus_ref) * 100, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Results reference versus candidate 1 sacrebleu library BLEU: \",\n",
    "    round(sacrebleu.corpus_bleu(wmt19_can_1, wmt19_ref_1).score, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEU score >40 is high quality! >60 is often better than human."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coursera",
   "language": "python",
   "name": "coursera"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
